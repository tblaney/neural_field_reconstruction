{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1TRXd4yLhGsYJxh1_vuogd-T7_uMn6B4J","timestamp":1714060788761},{"file_id":"1LkyW4CW1F90FlsIVKPjL3X5l7YKqHhMd","timestamp":1713975106501}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install trimesh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hXH9ISbnRst0","outputId":"2e8fa5bb-32e2-4137-8f62-381f4e189d4a","executionInfo":{"status":"ok","timestamp":1714150416282,"user_tz":420,"elapsed":22022,"user":{"displayName":"Traven Blaney","userId":"17518853465494486532"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting trimesh\n","  Downloading trimesh-4.3.1-py3-none-any.whl (693 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.8/693.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from trimesh) (1.25.2)\n","Installing collected packages: trimesh\n","Successfully installed trimesh-4.3.1\n"]}]},{"cell_type":"code","source":["!pip install libigl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2uggHF6UTGPO","outputId":"ed792c8b-baee-4674-cbd9-952ca80ced15","executionInfo":{"status":"ok","timestamp":1714150431675,"user_tz":420,"elapsed":15396,"user":{"displayName":"Traven Blaney","userId":"17518853465494486532"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting libigl\n","  Downloading libigl-2.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from libigl) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from libigl) (1.11.4)\n","Installing collected packages: libigl\n","Successfully installed libigl-2.5.1\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"LXI65HQLRlUL","executionInfo":{"status":"ok","timestamp":1714150439977,"user_tz":420,"elapsed":8304,"user":{"displayName":"Traven Blaney","userId":"17518853465494486532"}}},"outputs":[],"source":["import os\n","\n","import numpy as np\n","\n","import trimesh\n","\n","import torch\n","from torch.utils.data import Dataset\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm\n","\n","from scipy.spatial import KDTree\n","\n","from skimage import measure\n","\n","import igl\n","\n","import csv"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"pz_qJqk7h7gz","executionInfo":{"status":"ok","timestamp":1714150466415,"user_tz":420,"elapsed":26448,"user":{"displayName":"Traven Blaney","userId":"17518853465494486532"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4c2ab567-219c-4249-f1cd-44e1a4d2f8f5"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#@title dataloader\n","\n","class MeshDataset(Dataset):\n","    def __init__(self, mesh_path, device=torch.device('cuda:0'), subset=\"train\"):\n","        \"\"\"\n","        Initialize the dataset with the path to the mesh file, device configuration, subset selection,\n","        and debug mode.\n","\n","        Parameters:\n","            mesh_path (str): Path to the mesh file.\n","            device (torch.device): Device on which tensors will be created.\n","            subset (str): Specify whether to load the 'train' or 'validation' part of the dataset.\n","            debug (bool): If True, also load colors data for debugging purposes.\n","        \"\"\"\n","\n","        self.device = device\n","        self.subset = subset\n","\n","        # Load data\n","        self.points, self.labels = self.load_data(mesh_path)\n","        total_points = self.shuffle_data()\n","        self.split_data(total_points)\n","\n","\n","    def load_data(self, mesh_path):\n","        \"\"\"\n","        Load the mesh data from the file and extract vertices as points and colors for labeling.\n","\n","        Parameters:\n","            mesh_path (str): Path to the mesh file.\n","\n","        Returns:\n","            points, labels: Tensors representing vertices, their labels.\n","        \"\"\"\n","\n","        pcd = trimesh.load(mesh_path)\n","\n","        points = torch.tensor(pcd.vertices, dtype=torch.float32, device=self.device)\n","        colors = torch.tensor(pcd.visual.vertex_colors, dtype=torch.float32, device=self.device)[:, :3] / 255.\n","\n","        red_threshold = torch.tensor([1, 0, 0], device=self.device)\n","        green_threshold = torch.tensor([0, 1, 0], device=self.device)\n","\n","        self.points = points\n","        self.labels = torch.zeros(points.shape[0], dtype=torch.float32, device=self.device)\n","        self.labels[(colors == green_threshold).all(dim=1)] = 1\n","        self.labels[(colors == red_threshold).all(dim=1)] = 0\n","\n","        return self.points, self.labels\n","\n","    def shuffle_data(self):\n","        \"\"\"\n","        Shuffle the data to randomize the order of samples.\n","\n","        Returns:\n","            int: Total number of points (samples) after shuffling.\n","        \"\"\"\n","\n","        total_points = self.points.shape[0]\n","        permutation = torch.randperm(total_points)\n","        self.points = self.points[permutation]\n","        self.labels = self.labels[permutation]\n","\n","        return total_points\n","\n","    def split_data(self, total_points):\n","        \"\"\"\n","        Split the data into training or validation subsets based on the specified subset type.\n","\n","        Parameters:\n","            total_points (int): Total number of points in the dataset.\n","        \"\"\"\n","\n","        if self.subset == 'train':\n","            indices = torch.arange(0, int(0.8 * total_points))\n","        else:\n","            indices = torch.arange(int(0.8 * total_points), total_points)\n","\n","        # Apply the indices to subset the data.\n","        self.points = self.points[indices]\n","        self.labels = self.labels[indices]\n","\n","    def __len__(self):\n","        return self.points.shape[0]\n","\n","    def __getitem__(self, idx=None):\n","        if idx is None:\n","            idx = torch.randint(0, self.points.shape[0], (1,)).item()\n","\n","        return self.points[idx], self.labels[idx]"],"metadata":{"cellView":"form","id":"38hc8uMuItym","executionInfo":{"status":"ok","timestamp":1714150466620,"user_tz":420,"elapsed":206,"user":{"displayName":"Traven Blaney","userId":"17518853465494486532"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#@title utils\n","\n","def plot_points(path):\n","    ax = plt.figure().add_subplot(projection=\"3d\")\n","    obj = trimesh.load(path)\n","    x, y, z = obj.vertices[:, 0], obj.vertices[:, 1], obj.vertices[:, 2]\n","    mask = obj.colors[:, 1] == 255\n","    ax.scatter(\n","        x[mask], y[mask], zs=z[mask], zdir=\"y\", alpha=1, c=obj.colors[mask] / 255\n","    )\n","    ax.scatter(\n","        x[~mask], y[~mask], zs=z[~mask], zdir=\"y\", alpha=0.01, c=obj.colors[~mask] / 255\n","    )\n","    plt.show()\n","\n","\n","def download_data():\n","    import gdown\n","\n","    if not os.path.exists(\"./data\"):\n","        gdown.download_folder(\n","            \"https://drive.google.com/drive/folders/1EKWU_daQL3pxFkjFUomGs25_qekyfeAd\",\n","            quiet=False,\n","        )\n","\n","    if not os.path.exists(\"./processed\"):\n","        gdown.download_folder(\n","            \"https://drive.google.com/drive/folders/175_LtuWh1LknbbMjUumPjGzeSzgQ4ett\",\n","            quiet=False,\n","        )\n"],"metadata":{"id":"vLe0-yJ5R8ZX","cellView":"form","executionInfo":{"status":"ok","timestamp":1714150466621,"user_tz":420,"elapsed":3,"user":{"displayName":"Traven Blaney","userId":"17518853465494486532"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["EPSILON = 1e-15\n","IS_GOOGLE_COLAB = True\n","\n","CONFIG_HASH = \"hash\"\n","CONFIG_1LOD = \"one_lod\"\n","CONFIG_MLOD = \"m_lod\""],"metadata":{"id":"NerqvohhD6aB","executionInfo":{"status":"ok","timestamp":1714150466621,"user_tz":420,"elapsed":3,"user":{"displayName":"Traven Blaney","userId":"17518853465494486532"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["#@title trainer\n","\n","from torch.optim import Adam\n","from torch.nn import BCELoss\n","from torch.optim.lr_scheduler import StepLR\n","\n","import json\n","\n","class OccConfig:\n","    \"\"\"\n","    A configuration class to manage training options and hyperparameters, loaded from a JSON file.\n","    \"\"\"\n","    def __init__(self, name):\n","        self.name = name\n","        self.load_config(name)\n","        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","    def load_config(self, filename):\n","        \"\"\"\n","        Load configuration from a JSON file.\n","        \"\"\"\n","        try:\n","            if IS_GOOGLE_COLAB:\n","              with open(f\"drive/MyDrive/3dv_hw3/{filename}.json\", \"r\") as file:\n","                  data = json.load(file)\n","                  for key, value in data.items():\n","                      setattr(self, key, value)\n","            else:\n","              with open(f\"{filename}.json\", \"r\") as file:\n","                  data = json.load(file)\n","                  for key, value in data.items():\n","                      setattr(self, key, value)\n","\n","        except FileNotFoundError:\n","            raise FileNotFoundError(f\"no configuration file found for the name '{filename}'\")\n","        except json.JSONDecodeError:\n","            raise ValueError(\"error decoding JSON\")\n","\n","    def log_config(self):\n","        \"\"\"\n","        Log all configurations of the OccConfig instance.\n","        \"\"\"\n","        print(\"config settings:\")\n","        for attr, value in self.__dict__.items():\n","            print(f\"  {attr}: {value}\")\n","\n","\n","class OccTrainer:\n","    def __init__(self, config):\n","        \"\"\"\n","        Initializes the Trainer class with specified configuration options.\n","\n","        Parameters:\n","        config (OccConfig): Configuration options with training parameters and device settings.\n","        \"\"\"\n","        self.config = config\n","        self.device = config.device\n","\n","        self.train_dataset = MeshDataset(self.config.current_obj_path, device=self.device)\n","        self.train_dataloader = DataLoader(self.train_dataset, batch_size=self.config.batch_size, shuffle=True)\n","\n","        self.model = OCC(self.config).to(self.device)\n","\n","        self.optimizer = Adam(self.model.parameters(), lr=self.config.lr, betas=(0.9, 0.99), eps=EPSILON, weight_decay=self.config.weight_decay)\n","        self.criterion = BCELoss()\n","        self.scheduler = StepLR(self.optimizer, step_size=self.config.lr_decay_step, gamma=self.config.lr_decay_gamma)\n","\n","        self.num_epochs = self.config.epochs\n","\n","    def run(self):\n","        \"\"\"\n","        Run training for a specified number of epochs and save the best model based on loss.\n","        \"\"\"\n","\n","        self.model.train()\n","        best_loss = float('inf')\n","\n","        for epoch in range(self.num_epochs):\n","            total_loss = 0.0\n","            with tqdm(self.train_dataloader, unit=\"batch\") as pbar:\n","                for points, labels in pbar:\n","                    pbar.set_description(f\"epoch {epoch + 1}\")\n","                    labels = labels.view(-1, 1)\n","\n","                    # Zero out gradients\n","                    self.optimizer.zero_grad()\n","\n","                    # Form predictions\n","                    pred = self.model(points)\n","\n","                    # Calculate loss\n","                    loss = self.criterion(pred, labels)\n","\n","                    # Calculate gradients\n","                    loss.backward()\n","\n","                    # Step and backpropagate\n","                    self.optimizer.step()\n","                    self.scheduler.step()\n","\n","                    total_loss += loss.item()\n","\n","                    pbar.set_postfix(loss=total_loss / len(self.train_dataloader))\n","\n","                # Save if necessary\n","                if total_loss < best_loss:\n","                    best_loss = total_loss\n","                    current_obj_name = self.config.current_obj.replace(\".obj\", \"\")\n","                    if IS_GOOGLE_COLAB:\n","                        torch.save(self.model.state_dict(), f'drive/MyDrive/3dv_hw3/{self.config.name}_{current_obj_name}.pth')\n","                        print(\"model saved to: {}\".format(f'drive/MyDrive/3dv_hw3/{self.config.name}_{current_obj_name}.pth'))\n","                    else:\n","                        torch.save(self.model.state_dict(), f'{self.config.name}_{current_obj_name}.pth')\n","                    print(\"final model saved to: {}\".format(f'{self.config.name}_{current_obj_name}.pth'))\n","                elif epoch == self.num_epochs - 1:\n","                    current_obj_name = self.config.current_obj.replace(\".obj\", \"\")\n","                    torch.save(self.model.state_dict(), f'{self.config.name}_{current_obj_name}_final.pth')\n","                    print(\"final model saved to: {}\".format(f'{self.config.name}_{current_obj_name}_final.pth'))\n","\n","\n","    def get_num_params(self):\n","        \"\"\"\n","        Get the number of trainable parameters in the model.\n","\n","        Returns:\n","        int: Number of trainable parameters.\n","        \"\"\"\n","        return sum(p.numel() for p in self.model.parameters() if p.requires_grad)"],"metadata":{"id":"hBbWvZ4DSP1w","executionInfo":{"status":"ok","timestamp":1714150466789,"user_tz":420,"elapsed":171,"user":{"displayName":"Traven Blaney","userId":"17518853465494486532"}},"cellView":"form"},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#@title model\n","\n","class Baseline():\n","    def __init__(self, x, y):\n","        self.y = y\n","        self.tree = KDTree(x)\n","\n","    def __call__(self, x):\n","        _, idx = self.tree.query(x, k=3)\n","        return np.sign(self.y[idx].mean(axis=1))\n","\n","\n","def trilinear_interpolate(grid, pts, res, grid_type='dense'):\n","    \"\"\"\n","    Perform trilinear interpolation on a 3D grid at specified points. This function supports both\n","    dense grid structures and hashed grid representations.\n","\n","    Parameters:\n","        grid (torch.Tensor): The grid containing data values, either dense or indexed by hash values.\n","        pts (torch.Tensor): Coordinates of the points for which interpolation is desired. Points should\n","                            be normalized between -1 and 1.\n","        res (int): Resolution of the grid, assumed to be cubic (res x res x res).\n","        grid_type (str): Type of grid storage, 'dense' for direct storage or any other string for hashed storage.\n","\n","    Returns:\n","        torch.Tensor: Interpolated values at the input points.\n","    \"\"\"\n","\n","    PRIMES = [1, 265443567, 805459861]\n","\n","    # Resize grid\n","    if grid_type == 'dense':\n","        grid = grid.reshape(res, res, res, -1)\n","\n","    # Normalize\n","    xs = (pts[:, 0] + 1) * 0.5 * (res - 1)\n","    ys = (pts[:, 1] + 1) * 0.5 * (res - 1)\n","    zs = (pts[:, 2] + 1) * 0.5 * (res - 1)\n","\n","    # Base of voxel\n","    x0 = torch.floor(torch.clip(xs, 0, res - 1 - 1e-5)).long()\n","    y0 = torch.floor(torch.clip(ys, 0, res - 1 - 1e-5)).long()\n","    z0 = torch.floor(torch.clip(zs, 0, res - 1 - 1e-5)).long()\n","\n","    # Other corner\n","    x1 = x0 + 1\n","    y1 = y0 + 1\n","    z1 = z0 + 1\n","\n","    # Calculate weights\n","    w1 = ((x1 - xs) * (y1 - ys) * (z1 - zs)).unsqueeze(1)\n","    w2 = ((xs - x0) * (y1 - ys) * (z1 - zs)).unsqueeze(1)\n","    w3 = ((x1 - xs) * (ys - y0) * (z1 - zs)).unsqueeze(1)\n","    w4 = ((xs - x0) * (ys - y0) * (z1 - zs)).unsqueeze(1)\n","    w5 = ((x1 - xs) * (y1 - ys) * (zs - z0)).unsqueeze(1)\n","    w6 = ((xs - x0) * (y1 - ys) * (zs - z0)).unsqueeze(1)\n","    w7 = ((x1 - xs) * (ys - y0) * (zs - z0)).unsqueeze(1)\n","    w8 = ((xs - x0) * (ys - y0) * (zs - z0)).unsqueeze(1)\n","\n","    # Get values, which uses hashing function if hash case\n","    if grid_type == 'dense':\n","        v1 = grid[x0, y0, z0]\n","        v2 = grid[x1, y0, z0]\n","        v3 = grid[x0, y1, z0]\n","        v4 = grid[x1, y1, z0]\n","        v5 = grid[x0, y0, z1]\n","        v6 = grid[x1, y0, z1]\n","        v7 = grid[x0, y1, z1]\n","        v8 = grid[x1, y1, z1]\n","    else:\n","        id1 = (x0 * PRIMES[0] ^ y0 * PRIMES[1] ^ z0 * PRIMES[2]) % grid.shape[0]\n","        id2 = (x1 * PRIMES[0] ^ y0 * PRIMES[1] ^ z0 * PRIMES[2]) % grid.shape[0]\n","        id3 = (x0 * PRIMES[0] ^ y1 * PRIMES[1] ^ z0 * PRIMES[2]) % grid.shape[0]\n","        id4 = (x1 * PRIMES[0] ^ y1 * PRIMES[1] ^ z0 * PRIMES[2]) % grid.shape[0]\n","        id5 = (x0 * PRIMES[0] ^ y0 * PRIMES[1] ^ z1 * PRIMES[2]) % grid.shape[0]\n","        id6 = (x1 * PRIMES[0] ^ y0 * PRIMES[1] ^ z1 * PRIMES[2]) % grid.shape[0]\n","        id7 = (x0 * PRIMES[0] ^ y1 * PRIMES[1] ^ z1 * PRIMES[2]) % grid.shape[0]\n","        id8 = (x1 * PRIMES[0] ^ y1 * PRIMES[1] ^ z1 * PRIMES[2]) % grid.shape[0]\n","\n","        v1 = grid[id1]\n","        v2 = grid[id2]\n","        v3 = grid[id3]\n","        v4 = grid[id4]\n","        v5 = grid[id5]\n","        v6 = grid[id6]\n","        v7 = grid[id7]\n","        v8 = grid[id8]\n","\n","    # Lerp\n","    out = w1 * v1 + w2 * v2 + w3 * v3 + w4 * v4 + w5 * v5 + w6 * v6 + w7 * v7 + w8 * v8\n","\n","    return out\n","\n","\n","class Baseline():\n","    def __init__(self, x, y):\n","        self.y = y\n","        self.tree = KDTree(x)\n","\n","    def __call__(self, x):\n","        _, idx = self.tree.query(x, k=3)\n","        return np.sign(self.y[idx].mean(axis=1))\n","\n","\n","class DenseGrid(nn.Module):\n","    def __init__(self, base_lod, num_lods, feature_dimension, device='cuda'):\n","        \"\"\"\n","        Initializes the DenseGrid module for handling multiple levels of detail (LOD) in a dense grid.\n","\n","        Parameters:\n","        base_lod (int): The base level of detail, where each LOD corresponds to a grid of size (2^LOD)^3.\n","        num_lods (int): Number of levels of detail to generate starting from the base_lod.\n","        feature_dimension (int): The dimensionality of features at each point in the grid.\n","        device (str): Device to which the grid tensors will be allocated ('cuda' or 'cpu').\n","        \"\"\"\n","        super(DenseGrid, self).__init__()\n","\n","        # Define grid resolutions based on lod size args\n","        self.lod_sizes = [2 ** l for l in range(base_lod, base_lod + num_lods)]\n","\n","        self.feature_dimension = feature_dimension\n","        self.device = device\n","\n","        self.initialize_feature_grids()\n","\n","    def initialize_feature_grids(self):\n","        \"\"\"\n","        Initialize the feature grids for each level of detail as a Parameter in ParameterList.\n","        Each grid is initialized to have a normal distribution around mean 0 with a standard deviation of 0.01.\n","        \"\"\"\n","        self.feature_grids = nn.ParameterList()\n","\n","        for grid_size in self.lod_sizes:\n","            grid_features = nn.Parameter(torch.zeros(grid_size ** 3, self.feature_dimension, dtype=torch.float32, device=self.device))\n","            nn.init.normal_(grid_features, mean=0, std=0.01)\n","            self.feature_grids.append(grid_features)\n","\n","    def forward(self, points):\n","        \"\"\"\n","        Define the forward pass for interpolating features at the given points from multiple levels of detail.\n","\n","        Parameters:\n","        points (Tensor): Tensor of size (num_points, 3) containing the coordinates of points where features are to be interpolated.\n","\n","        Returns:\n","        Tensor: Concatenated features from all levels of detail for the input points.\n","        \"\"\"\n","\n","        interpolated_features = []\n","        for lod_size, grid_features in zip(self.lod_sizes, self.feature_grids):\n","            interpolated_feature = trilinear_interpolate(grid_features, points, lod_size, grid_type='dense')\n","            interpolated_features.append(interpolated_feature)\n","\n","        return torch.cat(interpolated_features, dim=-1)\n","\n","\n","class HashGrid(nn.Module):\n","    def __init__(self, minimum_resolution, maximum_resolution, num_lods, hash_bandwidth, feature_dimension, device='cuda'):\n","        \"\"\"\n","        Initializes the HashGrid module for spatial hashing at multiple levels of detail.\n","\n","        Parameters:\n","        minimum_resolution (int): Minimum resolution size at the lowest level of detail.\n","        maximum_resolution (int): Maximum resolution size at the highest level of detail.\n","        num_lods (int): Number of levels of detail to manage.\n","        hash_bandwidth (int): Log base 2 of the number of buckets in the hash table.\n","        feature_dimension (int): The dimensionality of features at each hash grid point.\n","        device (str): Device to which the grid tensors will be allocated ('cuda' or 'cpu').\n","        \"\"\"\n","        super(HashGrid, self).__init__()\n","\n","        self.minimum_resolution = minimum_resolution\n","        self.maximum_resolution = maximum_resolution\n","\n","        self.num_lods = num_lods\n","        self.feature_dimension = feature_dimension\n","        self.device = device\n","        self.hash_table_size = 2 ** hash_bandwidth\n","\n","        # Calculate the base for exponential growth of resolutions across LODs\n","        base_growth = np.exp((np.log(self.maximum_resolution) - np.log(self.minimum_resolution)) / (self.num_lods - 1))\n","        self.lod_resolutions = [int(1 + np.floor(self.minimum_resolution * (base_growth ** l))) for l in range(self.num_lods)]\n","\n","        self.initialize_feature_grids()\n","\n","    def initialize_feature_grids(self):\n","        \"\"\"\n","        Initialize the feature grids for each level of detail as a Parameter in ParameterList.\n","        Each grid is limited by the hash table size and initialized to have a normal distribution with a very small standard deviation.\n","        \"\"\"\n","\n","        self.feature_grids = nn.ParameterList()\n","\n","        for lod_size in self.lod_resolutions:\n","            grid_features = nn.Parameter(\n","                torch.zeros(min(lod_size ** 3, self.hash_table_size), self.feature_dimension, dtype=torch.float32, device=self.device))\n","            nn.init.normal_(grid_features, mean=0, std=0.001)\n","            self.feature_grids.append(grid_features)\n","\n","    def forward(self, points):\n","        \"\"\"\n","        Define the forward pass for interpolating features at the given points from multiple levels of detail.\n","\n","        Parameters:\n","        points (Tensor): Tensor of size (num_points, 3) containing the coordinates of points where features are to be interpolated.\n","\n","        Returns:\n","        Tensor: Concatenated features from all levels of detail for the input points.\n","        \"\"\"\n","\n","        interpolated_features = []\n","\n","        for lod_size, grid_features in zip(self.lod_resolutions, self.feature_grids):\n","            if points.dim() != 2 or points.shape[1] != 3:\n","              raise ValueError(f\"expected points to be [num_points, 3], got: {points.shape}\")\n","\n","            interpolated_feature = trilinear_interpolate(grid_features, points, lod_size, grid_type='hash')\n","            interpolated_features.append(interpolated_feature)\n","\n","        concatenated_features = torch.cat(interpolated_features, dim=-1)\n","\n","        return concatenated_features\n","\n","\n","class MLP(nn.Module):\n","    def __init__(self, num_layers, layer_width, feature_dimension, num_lods):\n","        \"\"\"\n","        Initializes a multilayer perceptron (MLP) with specified parameters.\n","\n","        Parameters:\n","        num_layers (int): Number of layers in the MLP, excluding the input and output layers.\n","        layer_width (int): The number of neurons in each hidden layer.\n","        feature_dimension (int): The dimensionality of the input features per level of detail.\n","        num_lods (int): The number of different levels of detail, which influences input dimension.\n","\n","        The network architecture follows this sequence: Input Layer -> (num_layers) Hidden Layers -> Output Layer.\n","        \"\"\"\n","        super(MLP, self).__init__()\n","\n","        self.num_layers = num_layers\n","        self.layer_width = layer_width\n","\n","        self.initialize_layers(feature_dimension, num_lods)\n","        self.initialize_weights()\n","\n","    def initialize_layers(self, feature_dimension, num_lods):\n","        \"\"\"\n","        Construct the layers of the MLP from the input to the output layer.\n","\n","        Parameters:\n","            feature_dimension (int): Dimensionality of input features per level of detail.\n","            num_lods (int): Number of levels of detail, determining the input size.\n","\n","        This method builds each layer and adds ReLU activations after each hidden layer.\n","        \"\"\"\n","\n","        self.layers = nn.ModuleList()\n","        input_dimension = feature_dimension * num_lods\n","\n","        self.layers.append(nn.Linear(input_dimension, self.layer_width))\n","        self.layers.append(nn.ReLU())\n","\n","        for _ in range(self.num_layers - 1):\n","            self.layers.append(nn.Linear(self.layer_width, self.layer_width))\n","            self.layers.append(nn.ReLU())\n","\n","        self.layers.append(nn.Linear(self.layer_width, 1))\n","        self.layers = nn.Sequential(*self.layers)\n","\n","    def initialize_weights(self):\n","        \"\"\"\n","        Initialize weights using the Xavier uniform initializer for better initial weights distribution.\n","        \"\"\"\n","        for layer in self.layers:\n","            if isinstance(layer, nn.Linear):\n","                nn.init.xavier_uniform_(layer.weight)\n","\n","    def forward(self, inputs):\n","        \"\"\"\n","        Defines the forward pass of the MLP using the Sequential model defined.\n","\n","        Parameters:\n","        inputs (Tensor): The input tensor to the MLP.\n","\n","        Returns:\n","        Tensor: Output tensor after processing through MLP and applying sigmoid activation on the output layer.\n","        \"\"\"\n","        outputs = self.layers(inputs)\n","        outputs = torch.sigmoid(outputs)\n","        return outputs\n","\n","\n","\n","class OCC(nn.Module):\n","    def __init__(self, config):\n","        \"\"\"\n","        Initializes the OCC model which includes either a DenseGrid or HashGrid and an MLP for processing.\n","\n","        Parameters:\n","        config (object): Configuration object containing options like grid type, dimensions, and model parameters.\n","        \"\"\"\n","        super(OCC, self).__init__()\n","\n","        self.config = config\n","        self.initialize_model()\n","\n","    def initialize_model(self):\n","        # Initialize the appropriate grid based on the configuration.\n","        if self.config.grid_type == 'dense':\n","            self.grid = DenseGrid(base_lod=self.config.base_lod, num_lods=self.config.num_lods,\n","                                  feature_dimension=self.config.grid_feature_dimension)\n","\n","            self.mlp = MLP(num_layers=self.config.num_mlp_layers, layer_width=self.config.mlp_width,\n","                       feature_dimension=self.config.grid_feature_dimension, num_lods=self.config.num_lods)\n","\n","        elif self.config.grid_type == 'hash':\n","            self.grid = HashGrid(minimum_resolution=2**self.config.base_lod,\n","                                 maximum_resolution=2**(self.config.base_lod + self.config.num_lods - 1),\n","                                 num_lods=self.config.num_lods, hash_bandwidth=13,\n","                                 feature_dimension=self.config.grid_feature_dimension)\n","\n","            self.mlp = MLP(num_layers=self.config.num_mlp_layers, layer_width=self.config.mlp_width,\n","                       feature_dimension=self.config.grid_feature_dimension, num_lods=self.config.num_lods)\n","        else:\n","            raise NotImplementedError('grid type \"{}\" not implemented'.format(self.config.grid_type))\n","\n","    def forward(self, inputs):\n","        \"\"\"\n","        Defines the forward pass through the grid and MLP.\n","\n","        Parameters:\n","        inputs (np.ndarray or Tensor): Input data, if numpy array, it will be converted to a Torch Tensor.\n","\n","        Returns:\n","        Tensor: The output of the MLP after processing inputs through the grid.\n","        \"\"\"\n","        if isinstance(inputs, np.ndarray):\n","            inputs = torch.from_numpy(inputs).float().cuda()\n","\n","        grid_output = self.grid(inputs)\n","        final_output = self.mlp(grid_output)\n","        return final_output\n"],"metadata":{"id":"c9woWygxSvLk","executionInfo":{"status":"ok","timestamp":1714150473685,"user_tz":420,"elapsed":191,"user":{"displayName":"Traven Blaney","userId":"17518853465494486532"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#@title reconstruction\n","\n","def generate_grid(point_cloud, resolutions):\n","    \"\"\"Generate grid over the point cloud with given resolution\n","    Args:\n","        point_cloud (np.array, [N, 3]): 3D coordinates of N points in space\n","        resolutions (int): grid resolution\n","    Returns:\n","        coords (np.array, [resolutions*resolutions*resolutions, 3]): grid vertices\n","        coords_matrix (np.array, [4, 4]): transform matrix: [0,resolutions]x[0,resolutions]x[0,resolutions] -> [x_min, x_max]x[y_min, y_max]x[z_min, z_max]\n","    \"\"\"\n","    b_min = np.min(point_cloud, axis=0)\n","    b_max = np.max(point_cloud, axis=0)\n","\n","    coords = np.mgrid[:resolutions, :resolutions, :resolutions]\n","    coords = coords.reshape(3, -1)\n","    coords_matrix = np.eye(4)\n","    length = b_max - b_min\n","    length += length / resolutions\n","    coords_matrix[0, 0] = length[0] / resolutions\n","    coords_matrix[1, 1] = length[1] / resolutions\n","    coords_matrix[2, 2] = length[2] / resolutions\n","    coords_matrix[0:3, 3] = b_min\n","    coords = np.matmul(coords_matrix[:3, :3], coords) + coords_matrix[:3, 3:4]\n","    coords = coords.T\n","\n","    return coords, coords_matrix\n","\n","\n","def batch_eval(points, eval_func, num_samples):\n","    \"\"\"Predict occupancy of values batch-wise\n","    Args:\n","        points (np.array, [N, 3]): 3D coordinates of N points in space\n","        eval_func (function): function that takes a batch of points and returns occupancy values\n","        num_samples (int): number of points to evaluate at once\n","    Returns:\n","        occ (np.array, [N,]): occupancy values for each point\n","    \"\"\"\n","\n","    num_pts = points.shape[0]\n","    occ = np.zeros(num_pts)\n","\n","    num_batches = num_pts // num_samples\n","    for i in range(num_batches):\n","        occ[i * num_samples: i * num_samples + num_samples] = eval_func(\n","            points[i * num_samples: i * num_samples + num_samples]\n","        ).detach().cpu().numpy().squeeze()\n","    if num_pts % num_samples:\n","        occ[num_batches * num_samples:] = eval_func(\n","            points[num_batches * num_samples:]\n","        ).detach().cpu().numpy().squeeze()\n","\n","    return occ\n","\n","\n","def eval_grid(coords, eval_func, num_per_sample=1024):\n","    \"\"\"Predict occupancy of values on a grid\n","    Args:\n","        coords (np.array, [N, 3]): 3D coordinates of N points in space\n","        eval_func (function): function that takes a batch of points and returns occupancy values\n","        num_per_sample (int): number of points to evaluate at once\n","\n","    Returns:\n","        occ (np.array, [N,]): occupancy values for each point\n","    \"\"\"\n","    coords = coords.reshape([-1, 3])\n","    occ = batch_eval(coords, eval_func, num_samples=num_per_sample)\n","    return occ\n","\n","\n","def reconstruct(model, grid, resolutions, transform):\n","    \"\"\"Reconstruct mesh by predicting occupancy values on a grid\n","    Args:\n","        model (function): function that takes a batch of points and returns occupancy values\n","        grid (np.array, [N, 3]): 3D coordinates of N points in space\n","        resolutions (int): grid resolution\n","        transform (np.array, [4, 4]): transform matrix: [0,resolutions]x[0,resolutions]x[0,resolutions] -> [x_min, x_max]x[y_min, y_max]x[z_min, z_max]\n","\n","    Returns:\n","        verts (np.array, [M, 3]): 3D coordinates of M vertices\n","        faces (np.array, [K, 3]): indices of K faces\n","    \"\"\"\n","\n","    occ = eval_grid(grid, model)\n","    occ = occ.reshape([resolutions, resolutions, resolutions])\n","\n","    # Correct surface level\n","    if occ.max() < 0.5:\n","        surface_level = None\n","    else:\n","        surface_level = 0.5\n","\n","    verts, faces, normals, values = measure.marching_cubes(occ, surface_level)\n","\n","    verts = np.matmul(transform[:3, :3], verts.T) + transform[:3, 3:4]\n","    verts = verts.T\n","\n","    return verts, faces\n","\n","\n","def compute_metrics(reconstr_path, gt_path, num_samples=1000000):\n","    \"\"\"Compute chamfer and hausdorff distances between the reconstructed mesh and the ground truth mesh\n","    Args:\n","        reconstr_path (str): path to the reconstructed mesh\n","        gt_path (str): path to the ground truth mesh\n","        num_samples (int): number of points to sample from each mesh\n","\n","    Returns:\n","        chamfer_dist (float): chamfer distance between the two meshes\n","        hausdorff_dist (float): hausdorff distance between the two meshes\n","    \"\"\"\n","    reconstr = trimesh.load(reconstr_path)\n","    gt = trimesh.load(gt_path)\n","\n","    # Sample points on the mesh surfaces using trimesh\n","    reconstr_pts = reconstr.sample(num_samples)\n","    gt_pts = gt.sample(num_samples)\n","\n","    # Compute chamfer distance between the two point clouds\n","    reconstr_tree = KDTree(reconstr_pts)\n","    gt_tree = KDTree(gt_pts)\n","    dist1, _ = reconstr_tree.query(gt_pts)\n","    dist2, _ = gt_tree.query(reconstr_pts)\n","    chamfer_dist = (dist1.mean() + dist2.mean()) / 2\n","    hausdorff_dist = max(dist1.max(), dist2.max())\n","\n","    return chamfer_dist, hausdorff_dist\n","\n","\n"],"metadata":{"cellView":"form","id":"kemiok70TwMN","executionInfo":{"status":"ok","timestamp":1714150475200,"user_tz":420,"elapsed":134,"user":{"displayName":"Traven Blaney","userId":"17518853465494486532"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#@title run - download data\n","\n","download_data()"],"metadata":{"cellView":"form","id":"ZwU4eQWOR73s","executionInfo":{"status":"ok","timestamp":1714150537314,"user_tz":420,"elapsed":60846,"user":{"displayName":"Traven Blaney","userId":"17518853465494486532"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"80a56057-a5a7-4733-a10b-50f85de5bdee"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["Retrieving folder contents\n"]},{"output_type":"stream","name":"stdout","text":["Processing file 1Ci7Az0sL16E3qmyJHhWKYtTRHPEhzEhu bunny.obj\n","Processing file 1yLoRg5vyAiZ4LXZqePD52uW5aSglapjZ column.obj\n","Processing file 1ceiguf2Hi9cLXddT5tozHOpnJeIQtVEs dragon_original.obj\n","Processing file 1-IsqDAFAseW5g_xaYGU5djm_-yOydURS serapis.obj\n","Processing file 1-0i_FDkwB39zUrPlU4zHR9KL7X5VPAsd utah_teapot.obj\n"]},{"output_type":"stream","name":"stderr","text":["Retrieving folder contents completed\n","Building directory structure\n","Building directory structure completed\n","Downloading...\n","From: https://drive.google.com/uc?id=1Ci7Az0sL16E3qmyJHhWKYtTRHPEhzEhu\n","To: /content/data/bunny.obj\n","100%|██████████| 5.55M/5.55M [00:00<00:00, 44.5MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1yLoRg5vyAiZ4LXZqePD52uW5aSglapjZ\n","To: /content/data/column.obj\n","100%|██████████| 4.04M/4.04M [00:00<00:00, 208MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1ceiguf2Hi9cLXddT5tozHOpnJeIQtVEs\n","To: /content/data/dragon_original.obj\n","100%|██████████| 74.9M/74.9M [00:00<00:00, 142MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1-IsqDAFAseW5g_xaYGU5djm_-yOydURS\n","To: /content/data/serapis.obj\n","100%|██████████| 7.03M/7.03M [00:00<00:00, 98.7MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1-0i_FDkwB39zUrPlU4zHR9KL7X5VPAsd\n","To: /content/data/utah_teapot.obj\n","100%|██████████| 699k/699k [00:00<00:00, 107MB/s]\n","Download completed\n","Retrieving folder contents\n"]},{"output_type":"stream","name":"stdout","text":["Processing file 1kKAM7Ba1or2Kjj4dwBlxjMBsM_QcKgbs bunny.obj\n","Processing file 1S0J22xgRxjbgC-dRkQTB8kaMZDAiVhtl column.obj\n","Processing file 1-YPoz8mmY5OS-P8kbBrzK9Wtbk60LpFJ dragon_original.obj\n","Processing file 1Dki_b4F3AxHuEe9Hi6nydrbjRxKRg_cu serapis.obj\n","Processing file 1lZhpryLdhyUksUD_McERjj5l4naM5Uxt utah_teapot.obj\n"]},{"output_type":"stream","name":"stderr","text":["Retrieving folder contents completed\n","Building directory structure\n","Building directory structure completed\n","Downloading...\n","From: https://drive.google.com/uc?id=1kKAM7Ba1or2Kjj4dwBlxjMBsM_QcKgbs\n","To: /content/processed/bunny.obj\n","100%|██████████| 18.3M/18.3M [00:00<00:00, 49.9MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1S0J22xgRxjbgC-dRkQTB8kaMZDAiVhtl\n","To: /content/processed/column.obj\n","100%|██████████| 18.2M/18.2M [00:00<00:00, 114MB/s] \n","Downloading...\n","From: https://drive.google.com/uc?id=1-YPoz8mmY5OS-P8kbBrzK9Wtbk60LpFJ\n","To: /content/processed/dragon_original.obj\n","100%|██████████| 18.2M/18.2M [00:00<00:00, 122MB/s] \n","Downloading...\n","From: https://drive.google.com/uc?id=1Dki_b4F3AxHuEe9Hi6nydrbjRxKRg_cu\n","To: /content/processed/serapis.obj\n","100%|██████████| 18.2M/18.2M [00:00<00:00, 110MB/s] \n","Downloading...\n","From: https://drive.google.com/uc?id=1lZhpryLdhyUksUD_McERjj5l4naM5Uxt\n","To: /content/processed/utah_teapot.obj\n","100%|██████████| 18.2M/18.2M [00:00<00:00, 137MB/s]\n","Download completed\n"]}]},{"cell_type":"code","source":["#@title download helper\n","\n","from google.colab import files\n","\n","def download_pth_file(file_path):\n","    \"\"\"\n","    Downloads a .pth file to the local machine from Google Colab.\n","\n","    Args:\n","    file_path (str): The path to the .pth file in the Colab environment.\n","    \"\"\"\n","    # Ensure the file exists before attempting to download\n","    try:\n","        # This will display a browser download prompt\n","        files.download(file_path)\n","    except FileNotFoundError:\n","        print(f\"The file {file_path} does not exist.\")\n","    except Exception as e:\n","        print(f\"An error occurred: {e}\")"],"metadata":{"cellView":"form","id":"kx919DupBfzy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title run - train\n","\n","config = OccConfig(CONFIG_1LOD)\n","\n","print(f'load config: {config.name}')\n","\n","for obj_file in os.listdir(\"processed\"):\n","\n","    print(\"##################\")\n","\n","    print(\"obj path: {}\".format(obj_file))\n","\n","    config.current_obj_path = \"processed/{}\".format(obj_file)\n","    config.current_obj = obj_file\n","\n","    config.log_config()\n","\n","    current_obj_name = config.current_obj.replace(\".obj\", \"\")\n","\n","    trainer = OccTrainer(config)\n","\n","    print('model has {} params!'.format(trainer.get_num_params()))\n","\n","    print(\"##################\")\n","\n","    trainer.run()\n"],"metadata":{"id":"EEDLnlYnuGUz","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title run - reconstruction\n","\n","\n","# Open up a results file to save\n","with open(\"results.csv\", mode=\"a+\", encoding=\"utf-8\") as file:\n","\n","    results = csv.writer(file)\n","    results.writerow([\"Mesh\", \"Type\", \"Resolution\", \"Chamfer distance\", \"Hausdorff distance\"])\n","\n","    configs = [\"one_lod\", \"m_lod\", \"hash\"]\n","    resolutions = [64, 128, 256]\n","\n","    for current_object in os.listdir(\"processed\"):\n","        for name in configs:\n","\n","            config = OccConfig(name)\n","\n","            print(f\"processing {current_object}, type {name}\")\n","            model = OCC(config)\n","\n","            # Find model file\n","            current_object_name = current_object.replace(\".obj\", \"\")\n","            model_name = f\"drive/MyDrive/3dv_hw3/{name}_{current_object_name}_final.pth\"\n","\n","            if f\"{name}_{current_object_name}_final.pth\" not in os.listdir(\"drive/MyDrive/3dv_hw3\"):\n","                raise FileNotFoundError()\n","\n","            print(f\"found model at {model_name}\")\n","\n","            model.load_state_dict(torch.load(model_name))\n","            model.eval()\n","            model.to(config.device)\n","\n","            pc = trimesh.load(f\"processed/{current_object}\")\n","            verts = np.array(pc.vertices)\n","\n","            for resolution in resolutions:\n","\n","                print(f\"settings resolution at {resolution}\")\n","\n","                grid, transform = generate_grid(verts, resolutions=resolution)\n","                rec_verts, rec_faces = reconstruct(model, grid, resolution, transform)\n","\n","                reconstr_path = f\"reconstructions/{current_object.split('.')[0]}_{name}_{resolution}.obj\"\n","                os.makedirs(os.path.dirname(reconstr_path), exist_ok=True)\n","                trimesh.Trimesh(rec_verts, rec_faces).export(reconstr_path)\n","\n","                gt_path = f\"data/{current_object}\"\n","\n","                chamfer_dist, hausdorff_dist = compute_metrics(\n","                    reconstr_path, gt_path, num_samples=1000000\n","                )\n","\n","                results.writerow([current_object, name, resolution, chamfer_dist, hausdorff_dist])\n","\n","                print(current_object, name, resolution)\n","                print(f\"Chamfer distance: {chamfer_dist:.4f}\")\n","                print(f\"Hausdorff distance: {hausdorff_dist:.4f}\")\n","                print(\"##################\")\n","\n","                break\n","\n","            break\n","\n","        break"],"metadata":{"id":"0Rq970Aq5kcy","executionInfo":{"status":"ok","timestamp":1714150980024,"user_tz":420,"elapsed":442711,"user":{"displayName":"Traven Blaney","userId":"17518853465494486532"}},"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","outputId":"638ba1f1-da79-4b8f-e750-a535735e9a15"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["processing utah_teapot.obj, type one_lod\n","found model at drive/MyDrive/3dv_hw3/one_lod_utah_teapot_final.pth\n","settings resolution at 64\n","utah_teapot.obj one_lod 64\n","Chamfer distance: 0.0186\n","Hausdorff distance: 0.2061\n","##################\n"]}]}]}